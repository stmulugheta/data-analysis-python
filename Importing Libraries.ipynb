{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled8.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMT9IRM703fyN4iEoGpzrpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stmulugheta/data-analysis-python/blob/master/Importing%20Libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylC7m3PqDzud"
      },
      "source": [
        "# Basic Data anlaysis Steps in python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIlh9I7SHFeY"
      },
      "source": [
        " # Intall all the libraries you can import all your essential packages with one line of code and focus on what is important? \n",
        " # The solution is called PyForest.\n",
        " # PyForest is a lazy import. As the name says, it imports the most popular Data Science libraries for Python. \n",
        " #The PyForest developers aim to import 99% of all the most used libraries."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-60_YQHvIEO1",
        "outputId": "de0c9ea3-585a-4813-f35d-7cbf1b8cbea4"
      },
      "source": [
        "#Install PyForest\n",
        "!pip install pyforest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyforest\n",
            "  Downloading pyforest-1.1.0.tar.gz (15 kB)\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.1.0-py2.py3-none-any.whl size=14607 sha256=7b14582e6a70bc5ff5d4e65dc3781f0c93fbfc374c48c31e44931328aed6271a\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1c/da/48e6c884142d485475d852d69d20a096aba5beceb338822893\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrMH6L2gIaAu"
      },
      "source": [
        "#To import, you can use\n",
        "import pyforest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeLuU7aqIpOm"
      },
      "source": [
        "# OR \n",
        "from pyforest import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXFAmeLXIy_-"
      },
      "source": [
        "# what is actually being imported?\n",
        "# Pandas, NumPy, Matplotlib, Seaborn, Sklearn, Keras, NLTK, and the list goes on and on"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crPp586VI1Ze",
        "outputId": "92d12aa0-77f9-452e-caff-37195b23e20e"
      },
      "source": [
        "# You can find a omplete list of libraries typing lazy_imports() and you will be able to see the full list.\n",
        "lazy_imports()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['from sklearn.ensemble import GradientBoostingRegressor',\n",
              " 'from sklearn.linear_model import Ridge',\n",
              " 'from sklearn.ensemble import GradientBoostingClassifier',\n",
              " 'from sklearn.preprocessing import MinMaxScaler',\n",
              " 'import sklearn',\n",
              " 'import gensim',\n",
              " 'from sklearn.linear_model import LinearRegression',\n",
              " 'import plotly.graph_objs as go',\n",
              " 'from sklearn.preprocessing import LabelEncoder',\n",
              " 'import nltk',\n",
              " 'from xlrd import open_workbook',\n",
              " 'import os',\n",
              " 'import pickle',\n",
              " 'from sklearn.decomposition import PCA',\n",
              " 'import numpy as np',\n",
              " 'import altair as alt',\n",
              " 'from sklearn.preprocessing import RobustScaler',\n",
              " 'from pyspark import SparkContext',\n",
              " 'import pandas as pd',\n",
              " 'import imutils',\n",
              " 'import tensorflow as tf',\n",
              " 'from statsmodels.tsa.arima_model import ARIMA',\n",
              " 'from sklearn.manifold import TSNE',\n",
              " 'import statistics',\n",
              " 'from sklearn import metrics',\n",
              " 'from sklearn.feature_extraction.text import CountVectorizer',\n",
              " 'import keras',\n",
              " 'import fastai',\n",
              " 'from PIL import Image',\n",
              " 'from dask import dataframe as dd',\n",
              " 'from sklearn.model_selection import GridSearchCV',\n",
              " 'from sklearn.linear_model import ElasticNet',\n",
              " 'from scipy import signal as sg',\n",
              " 'from sklearn.cluster import KMeans',\n",
              " 'from sklearn.model_selection import StratifiedKFold',\n",
              " 'from sklearn import svm',\n",
              " 'import awswrangler as wr',\n",
              " 'import matplotlib.pyplot as plt',\n",
              " 'from sklearn.linear_model import Lasso',\n",
              " 'import textblob',\n",
              " 'import sys',\n",
              " 'import pydot',\n",
              " 'from scipy import stats',\n",
              " 'import statsmodels.api as sm',\n",
              " 'from sklearn.impute import SimpleImputer',\n",
              " 'import matplotlib as mpl',\n",
              " 'import re',\n",
              " 'from sklearn.model_selection import KFold',\n",
              " 'import xgboost as xgb',\n",
              " 'import torch',\n",
              " 'import bokeh',\n",
              " 'from sklearn.preprocessing import PolynomialFeatures',\n",
              " 'import datetime as dt',\n",
              " 'import plotly as py',\n",
              " 'import fbprophet',\n",
              " 'from sklearn.linear_model import ElasticNetCV',\n",
              " 'from sklearn.model_selection import train_test_split',\n",
              " 'from sklearn.preprocessing import StandardScaler',\n",
              " 'from sklearn.ensemble import RandomForestClassifier',\n",
              " 'import seaborn as sns',\n",
              " 'import tqdm',\n",
              " 'from sklearn.model_selection import RandomizedSearchCV',\n",
              " 'import glob',\n",
              " 'import cv2',\n",
              " 'from sklearn.linear_model import LassoCV',\n",
              " 'from pathlib import Path',\n",
              " 'import spacy',\n",
              " 'from sklearn.ensemble import RandomForestRegressor',\n",
              " 'from sklearn.linear_model import LogisticRegression',\n",
              " 'from sklearn.feature_extraction.text import TfidfVectorizer',\n",
              " 'from fbprophet import Prophet',\n",
              " 'import dash',\n",
              " 'import skimage',\n",
              " 'import plotly.express as px',\n",
              " 'from sklearn.linear_model import RidgeCV',\n",
              " 'from sklearn.model_selection import cross_val_score']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln5mYrcDJlcl",
        "outputId": "c6fcc7e2-c4aa-43f4-fc06-e028ca5b68f3"
      },
      "source": [
        "# Adding more libraries to PyForest\n",
        "!pip show pyforest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pyforest\n",
            "Version: 1.1.0\n",
            "Summary: Lazy-import of all popular Python Data Science libraries. Stop writing the same imports over and over again.\n",
            "Home-page: https://github.com/8080labs/pyforest/\n",
            "Author: Florian Wetschoreck, Guido Drechsel, Tobias Krabel\n",
            "Author-email: info@8080labs.com\n",
            "License: mit\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    }
  ]
}